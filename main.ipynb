{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Huzeyfe Bıçakçı\n",
    "#import libraries\n",
    "\n",
    "from numpy import loadtxt #loads the data fromm a textfile and stores them n dimensional array\n",
    "from keras.models import Sequential #sequential ANN model\n",
    "from keras.layers import Dense #dense layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the dataset\n",
    "\n",
    "dataset = loadtxt('diabeticPersonsDataset.csv', delimiter=',')\n",
    "\n",
    "#Split into Input which is X , and output which is Y (viariables)\n",
    "X = dataset[:,0:8] # 0-7 columns are eight features of datasets (columns)\n",
    "y = dataset[:,8]   #last column is predicted value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation= 'relu')) #8 inputs data,12 neuron in first hidden layer,activation function is RELU\n",
    "model.add(Dense(8, activation= 'relu'))               #8 neurons in second hidden layer,activation function is RELU\n",
    "model.add(Dense(1, activation='sigmoid'))             #1 output node,activation fucnction is sigmoid because its a classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile the keras model\n",
    "model.compile(loss='binary_crossentropy', optimizer= 'adam', metrics = ['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "32/32 [==============================] - 0s 807us/step - loss: 2.7626 - accuracy: 0.6055\n",
      "Epoch 2/250\n",
      "32/32 [==============================] - 0s 936us/step - loss: 1.5232 - accuracy: 0.6003\n",
      "Epoch 3/250\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2839 - accuracy: 0.6159\n",
      "Epoch 4/250\n",
      "32/32 [==============================] - 0s 835us/step - loss: 1.1382 - accuracy: 0.6133\n",
      "Epoch 5/250\n",
      "32/32 [==============================] - 0s 806us/step - loss: 0.9997 - accuracy: 0.6146\n",
      "Epoch 6/250\n",
      "32/32 [==============================] - 0s 774us/step - loss: 0.9012 - accuracy: 0.6224\n",
      "Epoch 7/250\n",
      "32/32 [==============================] - 0s 885us/step - loss: 0.8472 - accuracy: 0.6146\n",
      "Epoch 8/250\n",
      "32/32 [==============================] - 0s 695us/step - loss: 0.7920 - accuracy: 0.6302\n",
      "Epoch 9/250\n",
      "32/32 [==============================] - 0s 774us/step - loss: 0.7744 - accuracy: 0.6315\n",
      "Epoch 10/250\n",
      "32/32 [==============================] - 0s 916us/step - loss: 0.7502 - accuracy: 0.6250\n",
      "Epoch 11/250\n",
      "32/32 [==============================] - 0s 728us/step - loss: 0.7353 - accuracy: 0.6354\n",
      "Epoch 12/250\n",
      "32/32 [==============================] - 0s 903us/step - loss: 0.7065 - accuracy: 0.6432\n",
      "Epoch 13/250\n",
      "32/32 [==============================] - 0s 728us/step - loss: 0.6948 - accuracy: 0.6510\n",
      "Epoch 14/250\n",
      "32/32 [==============================] - 0s 807us/step - loss: 0.6924 - accuracy: 0.6497\n",
      "Epoch 15/250\n",
      "32/32 [==============================] - 0s 742us/step - loss: 0.6751 - accuracy: 0.6523\n",
      "Epoch 16/250\n",
      "32/32 [==============================] - 0s 871us/step - loss: 0.6755 - accuracy: 0.6536\n",
      "Epoch 17/250\n",
      "32/32 [==============================] - 0s 839us/step - loss: 0.6693 - accuracy: 0.6706\n",
      "Epoch 18/250\n",
      "32/32 [==============================] - 0s 838us/step - loss: 0.6478 - accuracy: 0.6523\n",
      "Epoch 19/250\n",
      "32/32 [==============================] - 0s 740us/step - loss: 0.6375 - accuracy: 0.6615\n",
      "Epoch 20/250\n",
      "32/32 [==============================] - 0s 832us/step - loss: 0.6335 - accuracy: 0.6471\n",
      "Epoch 21/250\n",
      "32/32 [==============================] - 0s 903us/step - loss: 0.6245 - accuracy: 0.6667\n",
      "Epoch 22/250\n",
      "32/32 [==============================] - 0s 909us/step - loss: 0.6204 - accuracy: 0.6732\n",
      "Epoch 23/250\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6136 - accuracy: 0.6706\n",
      "Epoch 24/250\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6040 - accuracy: 0.7005\n",
      "Epoch 25/250\n",
      "32/32 [==============================] - 0s 703us/step - loss: 0.6001 - accuracy: 0.6888\n",
      "Epoch 26/250\n",
      "32/32 [==============================] - 0s 839us/step - loss: 0.5895 - accuracy: 0.6862\n",
      "Epoch 27/250\n",
      "32/32 [==============================] - 0s 890us/step - loss: 0.5909 - accuracy: 0.6849\n",
      "Epoch 28/250\n",
      "32/32 [==============================] - 0s 744us/step - loss: 0.5901 - accuracy: 0.6914\n",
      "Epoch 29/250\n",
      "32/32 [==============================] - 0s 690us/step - loss: 0.5888 - accuracy: 0.6888\n",
      "Epoch 30/250\n",
      "32/32 [==============================] - 0s 742us/step - loss: 0.5903 - accuracy: 0.6849\n",
      "Epoch 31/250\n",
      "32/32 [==============================] - 0s 903us/step - loss: 0.5751 - accuracy: 0.7214\n",
      "Epoch 32/250\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5800 - accuracy: 0.6992\n",
      "Epoch 33/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5762 - accuracy: 0.7044\n",
      "Epoch 34/250\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5715 - accuracy: 0.7135\n",
      "Epoch 35/250\n",
      "32/32 [==============================] - 0s 787us/step - loss: 0.5769 - accuracy: 0.7044\n",
      "Epoch 36/250\n",
      "32/32 [==============================] - 0s 937us/step - loss: 0.5689 - accuracy: 0.7135\n",
      "Epoch 37/250\n",
      "32/32 [==============================] - 0s 724us/step - loss: 0.5651 - accuracy: 0.7148\n",
      "Epoch 38/250\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5709 - accuracy: 0.7057\n",
      "Epoch 39/250\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5681 - accuracy: 0.7109\n",
      "Epoch 40/250\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5789 - accuracy: 0.7109\n",
      "Epoch 41/250\n",
      "32/32 [==============================] - 0s 738us/step - loss: 0.5674 - accuracy: 0.7070\n",
      "Epoch 42/250\n",
      "32/32 [==============================] - 0s 903us/step - loss: 0.5648 - accuracy: 0.7083\n",
      "Epoch 43/250\n",
      "32/32 [==============================] - 0s 759us/step - loss: 0.5679 - accuracy: 0.7018\n",
      "Epoch 44/250\n",
      "32/32 [==============================] - 0s 807us/step - loss: 0.5631 - accuracy: 0.7201\n",
      "Epoch 45/250\n",
      "32/32 [==============================] - 0s 788us/step - loss: 0.5661 - accuracy: 0.7018\n",
      "Epoch 46/250\n",
      "32/32 [==============================] - 0s 827us/step - loss: 0.5781 - accuracy: 0.7031\n",
      "Epoch 47/250\n",
      "32/32 [==============================] - 0s 841us/step - loss: 0.5797 - accuracy: 0.7109\n",
      "Epoch 48/250\n",
      "32/32 [==============================] - 0s 936us/step - loss: 0.5550 - accuracy: 0.7135\n",
      "Epoch 49/250\n",
      "32/32 [==============================] - 0s 744us/step - loss: 0.5644 - accuracy: 0.7201\n",
      "Epoch 50/250\n",
      "32/32 [==============================] - 0s 794us/step - loss: 0.5551 - accuracy: 0.7201\n",
      "Epoch 51/250\n",
      "32/32 [==============================] - 0s 807us/step - loss: 0.5519 - accuracy: 0.7331\n",
      "Epoch 52/250\n",
      "32/32 [==============================] - 0s 871us/step - loss: 0.5651 - accuracy: 0.7044\n",
      "Epoch 53/250\n",
      "32/32 [==============================] - 0s 710us/step - loss: 0.5516 - accuracy: 0.7096\n",
      "Epoch 54/250\n",
      "32/32 [==============================] - 0s 807us/step - loss: 0.5586 - accuracy: 0.7279\n",
      "Epoch 55/250\n",
      "32/32 [==============================] - 0s 746us/step - loss: 0.5468 - accuracy: 0.7253\n",
      "Epoch 56/250\n",
      "32/32 [==============================] - 0s 806us/step - loss: 0.5722 - accuracy: 0.7253\n",
      "Epoch 57/250\n",
      "32/32 [==============================] - 0s 964us/step - loss: 0.5650 - accuracy: 0.7135\n",
      "Epoch 58/250\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5519 - accuracy: 0.7279\n",
      "Epoch 59/250\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5430 - accuracy: 0.7253\n",
      "Epoch 60/250\n",
      "32/32 [==============================] - 0s 902us/step - loss: 0.5415 - accuracy: 0.7370\n",
      "Epoch 61/250\n",
      "32/32 [==============================] - 0s 902us/step - loss: 0.5419 - accuracy: 0.7370\n",
      "Epoch 62/250\n",
      "32/32 [==============================] - 0s 855us/step - loss: 0.5522 - accuracy: 0.7188\n",
      "Epoch 63/250\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5423 - accuracy: 0.7174\n",
      "Epoch 64/250\n",
      "32/32 [==============================] - 0s 824us/step - loss: 0.5382 - accuracy: 0.7357\n",
      "Epoch 65/250\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5407 - accuracy: 0.7474\n",
      "Epoch 66/250\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5414 - accuracy: 0.7357\n",
      "Epoch 67/250\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5589 - accuracy: 0.7227\n",
      "Epoch 68/250\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5519 - accuracy: 0.7201\n",
      "Epoch 69/250\n",
      "32/32 [==============================] - 0s 851us/step - loss: 0.5403 - accuracy: 0.7383\n",
      "Epoch 70/250\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5339 - accuracy: 0.7461\n",
      "Epoch 71/250\n",
      "32/32 [==============================] - 0s 941us/step - loss: 0.5461 - accuracy: 0.7292\n",
      "Epoch 72/250\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5443 - accuracy: 0.7240\n",
      "Epoch 73/250\n",
      "32/32 [==============================] - 0s 935us/step - loss: 0.5440 - accuracy: 0.7214\n",
      "Epoch 74/250\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5408 - accuracy: 0.7292\n",
      "Epoch 75/250\n",
      "32/32 [==============================] - 0s 903us/step - loss: 0.5333 - accuracy: 0.7331\n",
      "Epoch 76/250\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5325 - accuracy: 0.7383\n",
      "Epoch 77/250\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5423 - accuracy: 0.7214\n",
      "Epoch 78/250\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5358 - accuracy: 0.7370\n",
      "Epoch 79/250\n",
      "32/32 [==============================] - 0s 871us/step - loss: 0.5408 - accuracy: 0.7370\n",
      "Epoch 80/250\n",
      "32/32 [==============================] - 0s 838us/step - loss: 0.5356 - accuracy: 0.7383\n",
      "Epoch 81/250\n",
      "32/32 [==============================] - 0s 742us/step - loss: 0.5799 - accuracy: 0.7070\n",
      "Epoch 82/250\n",
      "32/32 [==============================] - 0s 806us/step - loss: 0.5477 - accuracy: 0.7253\n",
      "Epoch 83/250\n",
      "32/32 [==============================] - 0s 782us/step - loss: 0.5375 - accuracy: 0.7383\n",
      "Epoch 84/250\n",
      "32/32 [==============================] - 0s 710us/step - loss: 0.5716 - accuracy: 0.7044\n",
      "Epoch 85/250\n",
      "32/32 [==============================] - 0s 774us/step - loss: 0.5599 - accuracy: 0.7305\n",
      "Epoch 86/250\n",
      "32/32 [==============================] - 0s 839us/step - loss: 0.5341 - accuracy: 0.7370\n",
      "Epoch 87/250\n",
      "32/32 [==============================] - 0s 713us/step - loss: 0.5269 - accuracy: 0.7409\n",
      "Epoch 88/250\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5301 - accuracy: 0.7370\n",
      "Epoch 89/250\n",
      "32/32 [==============================] - 0s 742us/step - loss: 0.5286 - accuracy: 0.7318\n",
      "Epoch 90/250\n",
      "32/32 [==============================] - 0s 871us/step - loss: 0.5280 - accuracy: 0.7357\n",
      "Epoch 91/250\n",
      "32/32 [==============================] - 0s 790us/step - loss: 0.5340 - accuracy: 0.7305\n",
      "Epoch 92/250\n",
      "32/32 [==============================] - 0s 807us/step - loss: 0.5308 - accuracy: 0.7422\n",
      "Epoch 93/250\n",
      "32/32 [==============================] - 0s 759us/step - loss: 0.5275 - accuracy: 0.7279\n",
      "Epoch 94/250\n",
      "32/32 [==============================] - 0s 717us/step - loss: 0.5293 - accuracy: 0.7240\n",
      "Epoch 95/250\n",
      "32/32 [==============================] - 0s 717us/step - loss: 0.5224 - accuracy: 0.7435\n",
      "Epoch 96/250\n",
      "32/32 [==============================] - 0s 744us/step - loss: 0.5285 - accuracy: 0.7318\n",
      "Epoch 97/250\n",
      "32/32 [==============================] - 0s 679us/step - loss: 0.5252 - accuracy: 0.7448\n",
      "Epoch 98/250\n",
      "32/32 [==============================] - 0s 806us/step - loss: 0.5363 - accuracy: 0.7266\n",
      "Epoch 99/250\n",
      "32/32 [==============================] - 0s 702us/step - loss: 0.5216 - accuracy: 0.7422\n",
      "Epoch 100/250\n",
      "32/32 [==============================] - 0s 761us/step - loss: 0.5318 - accuracy: 0.7344\n",
      "Epoch 101/250\n",
      "32/32 [==============================] - 0s 806us/step - loss: 0.5324 - accuracy: 0.7331\n",
      "Epoch 102/250\n",
      "32/32 [==============================] - 0s 774us/step - loss: 0.5265 - accuracy: 0.7318\n",
      "Epoch 103/250\n",
      "32/32 [==============================] - 0s 807us/step - loss: 0.5315 - accuracy: 0.7331\n",
      "Epoch 104/250\n",
      "32/32 [==============================] - 0s 758us/step - loss: 0.5208 - accuracy: 0.7370\n",
      "Epoch 105/250\n",
      "32/32 [==============================] - 0s 774us/step - loss: 0.5194 - accuracy: 0.7448\n",
      "Epoch 106/250\n",
      "32/32 [==============================] - 0s 734us/step - loss: 0.5208 - accuracy: 0.7344\n",
      "Epoch 107/250\n",
      "32/32 [==============================] - 0s 742us/step - loss: 0.5168 - accuracy: 0.7500\n",
      "Epoch 108/250\n",
      "32/32 [==============================] - 0s 736us/step - loss: 0.5262 - accuracy: 0.7344\n",
      "Epoch 109/250\n",
      "32/32 [==============================] - 0s 713us/step - loss: 0.5250 - accuracy: 0.7357\n",
      "Epoch 110/250\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5264 - accuracy: 0.7409\n",
      "Epoch 111/250\n",
      "32/32 [==============================] - 0s 673us/step - loss: 0.5152 - accuracy: 0.7422\n",
      "Epoch 112/250\n",
      "32/32 [==============================] - 0s 935us/step - loss: 0.5156 - accuracy: 0.7396\n",
      "Epoch 113/250\n",
      "32/32 [==============================] - 0s 775us/step - loss: 0.5166 - accuracy: 0.7487\n",
      "Epoch 114/250\n",
      "32/32 [==============================] - 0s 935us/step - loss: 0.5195 - accuracy: 0.7383\n",
      "Epoch 115/250\n",
      "32/32 [==============================] - 0s 806us/step - loss: 0.5154 - accuracy: 0.7578\n",
      "Epoch 116/250\n",
      "32/32 [==============================] - 0s 1000us/step - loss: 0.5159 - accuracy: 0.7435\n",
      "Epoch 117/250\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5245 - accuracy: 0.7396\n",
      "Epoch 118/250\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5211 - accuracy: 0.7487\n",
      "Epoch 119/250\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5130 - accuracy: 0.7383\n",
      "Epoch 120/250\n",
      "32/32 [==============================] - 0s 871us/step - loss: 0.5181 - accuracy: 0.7292\n",
      "Epoch 121/250\n",
      "32/32 [==============================] - 0s 871us/step - loss: 0.5133 - accuracy: 0.7435\n",
      "Epoch 122/250\n",
      "32/32 [==============================] - 0s 839us/step - loss: 0.5129 - accuracy: 0.7526\n",
      "Epoch 123/250\n",
      "32/32 [==============================] - 0s 884us/step - loss: 0.5216 - accuracy: 0.7500\n",
      "Epoch 124/250\n",
      "32/32 [==============================] - 0s 808us/step - loss: 0.5095 - accuracy: 0.7422\n",
      "Epoch 125/250\n",
      "32/32 [==============================] - 0s 982us/step - loss: 0.5111 - accuracy: 0.7539\n",
      "Epoch 126/250\n",
      "32/32 [==============================] - 0s 742us/step - loss: 0.5407 - accuracy: 0.7370\n",
      "Epoch 127/250\n",
      "32/32 [==============================] - 0s 939us/step - loss: 0.5118 - accuracy: 0.7474\n",
      "Epoch 128/250\n",
      "32/32 [==============================] - 0s 774us/step - loss: 0.5202 - accuracy: 0.7461\n",
      "Epoch 129/250\n",
      "32/32 [==============================] - 0s 774us/step - loss: 0.5234 - accuracy: 0.7409\n",
      "Epoch 130/250\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5175 - accuracy: 0.7435\n",
      "Epoch 131/250\n",
      "32/32 [==============================] - 0s 766us/step - loss: 0.5220 - accuracy: 0.7448\n",
      "Epoch 132/250\n",
      "32/32 [==============================] - 0s 839us/step - loss: 0.5307 - accuracy: 0.7266\n",
      "Epoch 133/250\n",
      "32/32 [==============================] - 0s 709us/step - loss: 0.5129 - accuracy: 0.7591\n",
      "Epoch 134/250\n",
      "32/32 [==============================] - 0s 742us/step - loss: 0.5092 - accuracy: 0.7552\n",
      "Epoch 135/250\n",
      "32/32 [==============================] - 0s 741us/step - loss: 0.5131 - accuracy: 0.7448\n",
      "Epoch 136/250\n",
      "32/32 [==============================] - 0s 684us/step - loss: 0.4996 - accuracy: 0.7591\n",
      "Epoch 137/250\n",
      "32/32 [==============================] - 0s 715us/step - loss: 0.5096 - accuracy: 0.7487\n",
      "Epoch 138/250\n",
      "32/32 [==============================] - 0s 839us/step - loss: 0.5107 - accuracy: 0.7487\n",
      "Epoch 139/250\n",
      "32/32 [==============================] - 0s 806us/step - loss: 0.5048 - accuracy: 0.7474\n",
      "Epoch 140/250\n",
      "32/32 [==============================] - 0s 747us/step - loss: 0.5040 - accuracy: 0.7487\n",
      "Epoch 141/250\n",
      "32/32 [==============================] - 0s 756us/step - loss: 0.5040 - accuracy: 0.7656\n",
      "Epoch 142/250\n",
      "32/32 [==============================] - 0s 791us/step - loss: 0.5218 - accuracy: 0.7344\n",
      "Epoch 143/250\n",
      "32/32 [==============================] - 0s 732us/step - loss: 0.5130 - accuracy: 0.7435\n",
      "Epoch 144/250\n",
      "32/32 [==============================] - 0s 710us/step - loss: 0.5171 - accuracy: 0.7500\n",
      "Epoch 145/250\n",
      "32/32 [==============================] - 0s 733us/step - loss: 0.5062 - accuracy: 0.7500\n",
      "Epoch 146/250\n",
      "32/32 [==============================] - 0s 710us/step - loss: 0.5033 - accuracy: 0.7500\n",
      "Epoch 147/250\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5039 - accuracy: 0.7656\n",
      "Epoch 148/250\n",
      "32/32 [==============================] - 0s 674us/step - loss: 0.4994 - accuracy: 0.7578\n",
      "Epoch 149/250\n",
      "32/32 [==============================] - 0s 936us/step - loss: 0.5058 - accuracy: 0.7448\n",
      "Epoch 150/250\n",
      "32/32 [==============================] - 0s 743us/step - loss: 0.5095 - accuracy: 0.7461\n",
      "Epoch 151/250\n",
      "32/32 [==============================] - 0s 684us/step - loss: 0.5062 - accuracy: 0.7500\n",
      "Epoch 152/250\n",
      "32/32 [==============================] - 0s 780us/step - loss: 0.5013 - accuracy: 0.7643\n",
      "Epoch 153/250\n",
      "32/32 [==============================] - 0s 745us/step - loss: 0.5007 - accuracy: 0.7513\n",
      "Epoch 154/250\n",
      "32/32 [==============================] - 0s 742us/step - loss: 0.5021 - accuracy: 0.7630\n",
      "Epoch 155/250\n",
      "32/32 [==============================] - 0s 743us/step - loss: 0.5065 - accuracy: 0.7370\n",
      "Epoch 156/250\n",
      "32/32 [==============================] - 0s 871us/step - loss: 0.4954 - accuracy: 0.7591\n",
      "Epoch 157/250\n",
      "32/32 [==============================] - 0s 702us/step - loss: 0.5028 - accuracy: 0.7539\n",
      "Epoch 158/250\n",
      "32/32 [==============================] - 0s 871us/step - loss: 0.4985 - accuracy: 0.7526\n",
      "Epoch 159/250\n",
      "32/32 [==============================] - 0s 742us/step - loss: 0.4909 - accuracy: 0.7578\n",
      "Epoch 160/250\n",
      "32/32 [==============================] - 0s 806us/step - loss: 0.5195 - accuracy: 0.7422\n",
      "Epoch 161/250\n",
      "32/32 [==============================] - 0s 941us/step - loss: 0.4967 - accuracy: 0.7591\n",
      "Epoch 162/250\n",
      "32/32 [==============================] - 0s 742us/step - loss: 0.5009 - accuracy: 0.7552\n",
      "Epoch 163/250\n",
      "32/32 [==============================] - 0s 936us/step - loss: 0.5105 - accuracy: 0.7487\n",
      "Epoch 164/250\n",
      "32/32 [==============================] - 0s 710us/step - loss: 0.5113 - accuracy: 0.7435\n",
      "Epoch 165/250\n",
      "32/32 [==============================] - 0s 936us/step - loss: 0.5027 - accuracy: 0.7461\n",
      "Epoch 166/250\n",
      "32/32 [==============================] - 0s 839us/step - loss: 0.5043 - accuracy: 0.7591\n",
      "Epoch 167/250\n",
      "32/32 [==============================] - 0s 806us/step - loss: 0.4976 - accuracy: 0.7617\n",
      "Epoch 168/250\n",
      "32/32 [==============================] - 0s 871us/step - loss: 0.4933 - accuracy: 0.7487\n",
      "Epoch 169/250\n",
      "32/32 [==============================] - 0s 752us/step - loss: 0.4946 - accuracy: 0.7669\n",
      "Epoch 170/250\n",
      "32/32 [==============================] - 0s 924us/step - loss: 0.5057 - accuracy: 0.7383\n",
      "Epoch 171/250\n",
      "32/32 [==============================] - 0s 774us/step - loss: 0.4969 - accuracy: 0.7643\n",
      "Epoch 172/250\n",
      "32/32 [==============================] - 0s 758us/step - loss: 0.4968 - accuracy: 0.7604\n",
      "Epoch 173/250\n",
      "32/32 [==============================] - 0s 807us/step - loss: 0.4936 - accuracy: 0.7539\n",
      "Epoch 174/250\n",
      "32/32 [==============================] - 0s 750us/step - loss: 0.4968 - accuracy: 0.7604\n",
      "Epoch 175/250\n",
      "32/32 [==============================] - 0s 788us/step - loss: 0.5061 - accuracy: 0.7539\n",
      "Epoch 176/250\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5074 - accuracy: 0.7357\n",
      "Epoch 177/250\n",
      "32/32 [==============================] - 0s 767us/step - loss: 0.4929 - accuracy: 0.7669\n",
      "Epoch 178/250\n",
      "32/32 [==============================] - 0s 806us/step - loss: 0.4961 - accuracy: 0.7604\n",
      "Epoch 179/250\n",
      "32/32 [==============================] - 0s 751us/step - loss: 0.4892 - accuracy: 0.7721\n",
      "Epoch 180/250\n",
      "32/32 [==============================] - 0s 807us/step - loss: 0.4941 - accuracy: 0.7656\n",
      "Epoch 181/250\n",
      "32/32 [==============================] - 0s 703us/step - loss: 0.4966 - accuracy: 0.7526\n",
      "Epoch 182/250\n",
      "32/32 [==============================] - 0s 742us/step - loss: 0.5060 - accuracy: 0.7565\n",
      "Epoch 183/250\n",
      "32/32 [==============================] - 0s 737us/step - loss: 0.5017 - accuracy: 0.7552\n",
      "Epoch 184/250\n",
      "32/32 [==============================] - 0s 801us/step - loss: 0.4885 - accuracy: 0.7617\n",
      "Epoch 185/250\n",
      "32/32 [==============================] - 0s 718us/step - loss: 0.5068 - accuracy: 0.7526\n",
      "Epoch 186/250\n",
      "32/32 [==============================] - 0s 840us/step - loss: 0.4987 - accuracy: 0.7565\n",
      "Epoch 187/250\n",
      "32/32 [==============================] - 0s 743us/step - loss: 0.4968 - accuracy: 0.7539\n",
      "Epoch 188/250\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4924 - accuracy: 0.7435\n",
      "Epoch 189/250\n",
      "32/32 [==============================] - 0s 712us/step - loss: 0.4904 - accuracy: 0.7526\n",
      "Epoch 190/250\n",
      "32/32 [==============================] - 0s 895us/step - loss: 0.4981 - accuracy: 0.7617\n",
      "Epoch 191/250\n",
      "32/32 [==============================] - 0s 831us/step - loss: 0.4990 - accuracy: 0.7539\n",
      "Epoch 192/250\n",
      "32/32 [==============================] - 0s 809us/step - loss: 0.4933 - accuracy: 0.7565\n",
      "Epoch 193/250\n",
      "32/32 [==============================] - 0s 769us/step - loss: 0.4914 - accuracy: 0.7552\n",
      "Epoch 194/250\n",
      "32/32 [==============================] - 0s 800us/step - loss: 0.4973 - accuracy: 0.7565\n",
      "Epoch 195/250\n",
      "32/32 [==============================] - 0s 758us/step - loss: 0.4945 - accuracy: 0.7513\n",
      "Epoch 196/250\n",
      "32/32 [==============================] - 0s 775us/step - loss: 0.4888 - accuracy: 0.7721\n",
      "Epoch 197/250\n",
      "32/32 [==============================] - 0s 805us/step - loss: 0.4936 - accuracy: 0.7513\n",
      "Epoch 198/250\n",
      "32/32 [==============================] - 0s 763us/step - loss: 0.4959 - accuracy: 0.7552\n",
      "Epoch 199/250\n",
      "32/32 [==============================] - 0s 806us/step - loss: 0.4833 - accuracy: 0.7630\n",
      "Epoch 200/250\n",
      "32/32 [==============================] - 0s 755us/step - loss: 0.4984 - accuracy: 0.7591\n",
      "Epoch 201/250\n",
      "32/32 [==============================] - 0s 772us/step - loss: 0.4897 - accuracy: 0.7643\n",
      "Epoch 202/250\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4869 - accuracy: 0.7539\n",
      "Epoch 203/250\n",
      "32/32 [==============================] - 0s 801us/step - loss: 0.4932 - accuracy: 0.7526\n",
      "Epoch 204/250\n",
      "32/32 [==============================] - 0s 828us/step - loss: 0.4822 - accuracy: 0.7669\n",
      "Epoch 205/250\n",
      "32/32 [==============================] - 0s 805us/step - loss: 0.4939 - accuracy: 0.7591\n",
      "Epoch 206/250\n",
      "32/32 [==============================] - 0s 861us/step - loss: 0.4840 - accuracy: 0.7630\n",
      "Epoch 207/250\n",
      "32/32 [==============================] - 0s 775us/step - loss: 0.4840 - accuracy: 0.7721\n",
      "Epoch 208/250\n",
      "32/32 [==============================] - 0s 773us/step - loss: 0.4843 - accuracy: 0.7695\n",
      "Epoch 209/250\n",
      "32/32 [==============================] - 0s 783us/step - loss: 0.4857 - accuracy: 0.7617\n",
      "Epoch 210/250\n",
      "32/32 [==============================] - 0s 730us/step - loss: 0.4842 - accuracy: 0.7578\n",
      "Epoch 211/250\n",
      "32/32 [==============================] - 0s 807us/step - loss: 0.4859 - accuracy: 0.7826\n",
      "Epoch 212/250\n",
      "32/32 [==============================] - 0s 762us/step - loss: 0.4966 - accuracy: 0.7539\n",
      "Epoch 213/250\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4927 - accuracy: 0.7578\n",
      "Epoch 214/250\n",
      "32/32 [==============================] - 0s 752us/step - loss: 0.4787 - accuracy: 0.7682\n",
      "Epoch 215/250\n",
      "32/32 [==============================] - 0s 849us/step - loss: 0.4817 - accuracy: 0.7682\n",
      "Epoch 216/250\n",
      "32/32 [==============================] - 0s 779us/step - loss: 0.4775 - accuracy: 0.7721\n",
      "Epoch 217/250\n",
      "32/32 [==============================] - 0s 802us/step - loss: 0.5000 - accuracy: 0.7617\n",
      "Epoch 218/250\n",
      "32/32 [==============================] - 0s 713us/step - loss: 0.4913 - accuracy: 0.7565\n",
      "Epoch 219/250\n",
      "32/32 [==============================] - 0s 741us/step - loss: 0.4839 - accuracy: 0.7695\n",
      "Epoch 220/250\n",
      "32/32 [==============================] - 0s 824us/step - loss: 0.4819 - accuracy: 0.7617\n",
      "Epoch 221/250\n",
      "32/32 [==============================] - 0s 762us/step - loss: 0.4749 - accuracy: 0.7747\n",
      "Epoch 222/250\n",
      "32/32 [==============================] - 0s 741us/step - loss: 0.4797 - accuracy: 0.7630\n",
      "Epoch 223/250\n",
      "32/32 [==============================] - 0s 711us/step - loss: 0.4819 - accuracy: 0.7695\n",
      "Epoch 224/250\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4807 - accuracy: 0.7630\n",
      "Epoch 225/250\n",
      "32/32 [==============================] - 0s 840us/step - loss: 0.4797 - accuracy: 0.7708\n",
      "Epoch 226/250\n",
      "32/32 [==============================] - 0s 840us/step - loss: 0.4774 - accuracy: 0.7708\n",
      "Epoch 227/250\n",
      "32/32 [==============================] - 0s 903us/step - loss: 0.4868 - accuracy: 0.7604\n",
      "Epoch 228/250\n",
      "32/32 [==============================] - 0s 766us/step - loss: 0.4787 - accuracy: 0.7695\n",
      "Epoch 229/250\n",
      "32/32 [==============================] - 0s 776us/step - loss: 0.4774 - accuracy: 0.7721\n",
      "Epoch 230/250\n",
      "32/32 [==============================] - 0s 760us/step - loss: 0.4807 - accuracy: 0.7721\n",
      "Epoch 231/250\n",
      "32/32 [==============================] - 0s 728us/step - loss: 0.4860 - accuracy: 0.7591\n",
      "Epoch 232/250\n",
      "32/32 [==============================] - 0s 869us/step - loss: 0.4912 - accuracy: 0.7591\n",
      "Epoch 233/250\n",
      "32/32 [==============================] - 0s 746us/step - loss: 0.4836 - accuracy: 0.7643\n",
      "Epoch 234/250\n",
      "32/32 [==============================] - 0s 780us/step - loss: 0.4743 - accuracy: 0.7799\n",
      "Epoch 235/250\n",
      "32/32 [==============================] - 0s 746us/step - loss: 0.4723 - accuracy: 0.7760\n",
      "Epoch 236/250\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4795 - accuracy: 0.7747\n",
      "Epoch 237/250\n",
      "32/32 [==============================] - 0s 720us/step - loss: 0.4714 - accuracy: 0.7747\n",
      "Epoch 238/250\n",
      "32/32 [==============================] - 0s 942us/step - loss: 0.4791 - accuracy: 0.7760\n",
      "Epoch 239/250\n",
      "32/32 [==============================] - 0s 748us/step - loss: 0.4825 - accuracy: 0.7591\n",
      "Epoch 240/250\n",
      "32/32 [==============================] - 0s 874us/step - loss: 0.4855 - accuracy: 0.7669\n",
      "Epoch 241/250\n",
      "32/32 [==============================] - 0s 771us/step - loss: 0.4794 - accuracy: 0.7630\n",
      "Epoch 242/250\n",
      "32/32 [==============================] - 0s 780us/step - loss: 0.4772 - accuracy: 0.7734\n",
      "Epoch 243/250\n",
      "32/32 [==============================] - 0s 789us/step - loss: 0.4818 - accuracy: 0.7708\n",
      "Epoch 244/250\n",
      "32/32 [==============================] - 0s 774us/step - loss: 0.4871 - accuracy: 0.7734\n",
      "Epoch 245/250\n",
      "32/32 [==============================] - 0s 770us/step - loss: 0.4734 - accuracy: 0.7852\n",
      "Epoch 246/250\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4695 - accuracy: 0.7799\n",
      "Epoch 247/250\n",
      "32/32 [==============================] - 0s 722us/step - loss: 0.4661 - accuracy: 0.7826\n",
      "Epoch 248/250\n",
      "32/32 [==============================] - 0s 872us/step - loss: 0.4641 - accuracy: 0.7812\n",
      "Epoch 249/250\n",
      "32/32 [==============================] - 0s 773us/step - loss: 0.4696 - accuracy: 0.7799\n",
      "Epoch 250/250\n",
      "32/32 [==============================] - 0s 794us/step - loss: 0.4743 - accuracy: 0.7734\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d856b6a9b0>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the keras model on the dataset\n",
    "\n",
    "model.fit(X,y, epochs=250, batch_size=24) #fitting data in model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 696us/step - loss: 0.4640 - accuracy: 0.7747\n",
      "Accuracy: 77.47\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the keras model\n",
    "_, accuracy = model.evaluate(X,y)\n",
    "print ('Accuracy: %.2f' % (accuracy*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n",
      "X=[9, 170, 74, 31, 0, 44.0, 0.403, 43], Predicted=[0.8381827]\n"
     ]
    }
   ],
   "source": [
    "#predicting data\n",
    "xTest = ([[9,170,74,31,0,44.0,0.403,43]]) #the data which will be predict\n",
    "\n",
    "prediction = model.predict(xTest)\n",
    "\n",
    "print(\"X=%s, Predicted=%s\" % (xTest[0], prediction[0]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b1a1dad27b89ff3d8b1b7ad558b15a0eaf023a48140784a959c190c0e1cd6b40"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
